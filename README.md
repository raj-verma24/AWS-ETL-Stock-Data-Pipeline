# AWS-ETL-Stock-Data-Pipeline


## **ğŸ”¹ Overview**  
This project implements a **scalable ETL pipeline** using AWS services to ingest, process, and analyze **stock market data**. It leverages **Lambda, S3, Glue, and Redshift** for end-to-end data processing.


## **ğŸ”¹ AWS Services Used**  
âœ… **AWS Lambda** â†’ Fetches stock data automatically from an API  
âœ… **Amazon S3** â†’ Stores raw JSON and transformed data  
âœ… **AWS Glue** â†’ Crawls schema and processes data with PySpark  
âœ… **Amazon Redshift** â†’ Loads structured stock data for analytics  
âœ… **IAM Roles & Policies** â†’ Manages secure service access  



## **ğŸ”¹ ETL Pipeline Architecture**  
**Data Flow:**  

Stock Price API â†’ AWS Lambda â†’ S3 â†’ AWS Glue â†’ Redshift

## **ğŸ”¹ Folder Structure**

AWS-ETL-Stock-Data-Pipeline/
â”‚â”€â”€ lambda_scripts/               # Lambda function for data ingestion
â”‚   â”œâ”€â”€ fetch_stock_data.py
â”‚â”€â”€ glue_etl_jobs/                # PySpark scripts for ETL processing
â”‚   â”œâ”€â”€ stock_etl_job.py
â”‚â”€â”€ redshift_sql/                 # SQL queries for Redshift data loading & analysis
â”‚   â”œâ”€â”€ copy_to_redshift.sql
â”‚   â”œâ”€â”€ queries.sql
â”‚â”€â”€ iam_policies/                  # IAM role JSON policies for AWS services
â”‚   â”œâ”€â”€ s3_redshift_access.json
â”‚   â”œâ”€â”€ glue_execution_role.json
â”‚â”€â”€ architecture_diagram/         # Visual representation of AWS pipeline
â”‚   â”œâ”€â”€ aws_etl_pipeline.png
â”‚â”€â”€ README.md                      # Project documentation
â”‚â”€â”€ requirements.txt               # Dependencies for PySpark & AWS SDKs
â”‚â”€â”€ LICENSE                        # License file (Optional)
â”‚â”€â”€ .gitignore                     # Files to ignore in Git tracking


---

## **ğŸ”¹ Setup & Deployment**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/your-github-username/AWS-ETL-Stock-Data-Pipeline.git
cd AWS-ETL-Stock-Data-Pipeline

2ï¸âƒ£ Install Required Dependencie
```
Bash
pip install -r requirements.txt

```
3ï¸âƒ£ Configure AWS Credentials
Ensure your AWS CLI is set up correctly:
```
Bash
aws configure
```

ğŸ”¹ How It Works
ğŸ›  1ï¸âƒ£ Data Ingestion with AWS Lambda
- The Lambda function fetches stock price data every 5 minutes using an API
- Stores the raw JSON data in S3 (my-stock-data-bucket/raw/)
ğŸ“Œ Lambda Script: lambda_scripts/fetch_stock_data.py



ğŸ›  2ï¸âƒ£ Schema Detection with AWS Glue
- AWS Glue Crawler scans raw data in S3
- Automatically creates a structured table schema in AWS Glue Catalog
ğŸ“Œ Glue Catalog Table: stock_my_stock_data_bucket

ğŸ›  3ï¸âƒ£ ETL Processing with AWS Glue (PySpark)
- PySpark transformations extract timestamped stock prices
- Transformed data is stored in Parquet format in S3 (etl_output/)
ğŸ“Œ Glue ETL Script: glue_etl_jobs/stock_etl_job.py

î·™î·š

ğŸ›  4ï¸âƒ£ Loading into Amazon Redshift
- Redshift loads structured stock data for advanced analytics
- Uses IAM Role to grant permissions
ğŸ“Œ Redshift COPY Command: redshift_sql/copy_to_redshift.sql


ğŸ”¹ IAM Roles & Policies Configured
âœ” LambdaExecutionRole â†’ Grants Lambda access to write data into S3
âœ” GlueExecutionRole â†’ Allows Glue ETL jobs to read & process data
âœ” RedshiftS3AccessRole â†’ Enables Redshift to read transformed data from S3
âœ” S3 Bucket Policy â†’ Grants Redshift access via IAM
ğŸ“Œ See iam_policies/ for policy configurations

ğŸ”¹ Future Enhancements
âœ… Optimize PySpark transformations for better performance
âœ… Implement AWS Step Functions to orchestrate ETL workflows
âœ… Enable real-time stock trend predictions using AWS Athena

ğŸ”¹ Conclusion
ğŸ”¥ This AWS ETL pipeline successfully processes real-time stock data, enabling structured storage and analytics in Redshift!
ğŸ“Œ Want to discuss AWS-based ETL pipelines? Connect with me on LinkedIn! ğŸš€



